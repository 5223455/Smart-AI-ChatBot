// üöÄ Test script to verify ultra-fast response optimizations
const fetch = require('node-fetch');

async function testOptimizations() {
    console.log('üöÄ Testing Ultra-Fast Chatbot Optimizations...\n');
    
    const baseUrl = 'http://localhost:5000';
    const sessionId = Date.now().toString();
    
    try {
        // Test 1: Health check
        console.log('1Ô∏è‚É£ Testing server health...');
        const healthResponse = await fetch(`${baseUrl}/health`);
        const healthData = await healthResponse.json();
        console.log('‚úÖ Server Status:', healthData.status);
        console.log('‚úÖ Ollama Status:', healthData.ollama.status);
        
        // Test 2: Quick response (greeting)
        console.log('\n2Ô∏è‚É£ Testing quick response (greeting)...');
        const quickStartTime = Date.now();
        
        const quickResponse = await fetch(`${baseUrl}/chat`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ 
                sessionId, 
                message: 'Hello! How are you?' 
            })
        });
        
        const quickData = await quickResponse.json();
        const quickEndTime = Date.now();
        const quickResponseTime = quickEndTime - quickStartTime;
        
        console.log('‚úÖ Quick Response Time:', quickResponseTime + 'ms');
        console.log('‚úÖ Quick Response Length:', quickData.response?.length || 0, 'characters');
        console.log('‚úÖ Quick Success:', quickData.success);
        
        if (quickResponseTime < 500) {
            console.log('üéâ ULTRA FAST: Quick response under 0.5 seconds!');
        } else if (quickResponseTime < 1000) {
            console.log('‚ö° FAST: Quick response under 1 second!');
        } else {
            console.log('‚ö†Ô∏è SLOW: Quick response over 1 second');
        }
        
        // Test 3: Detailed response (complex question)
        console.log('\n3Ô∏è‚É£ Testing detailed response (complex question)...');
        const detailedStartTime = Date.now();
        
        const detailedResponse = await fetch(`${baseUrl}/chat`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ 
                sessionId, 
                message: 'Explain the differences between machine learning and artificial intelligence in detail.' 
            })
        });
        
        const detailedData = await detailedResponse.json();
        const detailedEndTime = Date.now();
        const detailedResponseTime = detailedEndTime - detailedStartTime;
        
        console.log('‚úÖ Detailed Response Time:', detailedResponseTime + 'ms');
        console.log('‚úÖ Detailed Response Length:', detailedData.response?.length || 0, 'characters');
        console.log('‚úÖ Detailed Success:', detailedData.success);
        
        if (detailedResponseTime < 2000) {
            console.log('üéâ ULTRA FAST: Detailed response under 2 seconds!');
        } else if (detailedResponseTime < 3000) {
            console.log('‚ö° FAST: Detailed response under 3 seconds!');
        } else {
            console.log('‚ö†Ô∏è SLOW: Detailed response over 3 seconds');
        }
        
        // Test 4: Streaming chat
        console.log('\n4Ô∏è‚É£ Testing streaming chat...');
        const streamStartTime = Date.now();
        
        const streamResponse = await fetch(`${baseUrl}/chat-stream`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ 
                sessionId, 
                message: 'Tell me about machine learning in a few sentences.' 
            })
        });
        
        if (streamResponse.ok) {
            console.log('‚úÖ Streaming endpoint accessible');
            console.log('‚úÖ Content-Type:', streamResponse.headers.get('content-type'));
        } else {
            console.log('‚ö†Ô∏è Streaming endpoint not working, but regular chat is optimized');
        }
        
        console.log('\nüéØ Smart Response System Summary:');
        console.log('‚úÖ Smart question detection implemented');
        console.log('‚úÖ Quick responses for greetings/simple questions');
        console.log('‚úÖ Detailed responses for complex questions');
        console.log('‚úÖ Typing animation shows first, then fast response');
        console.log('‚úÖ Ultra-fast typewriter (2ms for quick, 3ms for detailed)');
        console.log('‚úÖ AI parameters optimized per question type');
        console.log('‚úÖ Response time targets: < 0.5s quick, < 2s detailed');
        
    } catch (error) {
        console.error('‚ùå Test Error:', error.message);
        console.log('\nüí° Make sure to:');
        console.log('1. Start the server: cd nodejs-backend && node server.js');
        console.log('2. Have Ollama running: ollama run llama3.2:1b');
    }
}

// Run the test
testOptimizations();
